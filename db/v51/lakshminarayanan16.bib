@InProceedings{lakshminarayanan16,
  supplementary = {Supplementary:lakshminarayanan16-supp.pdf},
  title = {Mondrian Forests for Large-Scale Regression when Uncertainty Matters},
  author = {Lakshminarayanan, Balaji and Roy, Daniel M. and Teh, Yee Whye},
  pages = {1478-1487},
  abstract = {Many real-world regression problems demand a measure of the uncertainty associated with each prediction.  Standard decision forests deliver efficient state-of-the-art predictive performance, but high-quality uncertainty estimates are lacking. Gaussian processes (GPs) deliver uncertainty estimates, but scaling GPs to large-scale data sets comes at the cost of approximating the uncertainty estimates.  We extend Mondrian forests, first proposed by Lakshminarayanan et al. (2014) for classification problems, to the large-scale nonparametric regression setting. Using a novel hierarchical Gaussian prior that dovetails with the Mondrian forest framework, we obtain principled uncertainty estimates,  while still retaining the computational advantages of decision forests. Through a combination of illustrative examples, real-world large-scale datasets and Bayesian optimization benchmarks, we demonstrate that Mondrian forests outperform approximate GPs on large-scale regression tasks and deliver better-calibrated uncertainty assessments than decision-forest-based methods.},
}
