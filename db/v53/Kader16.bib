@InProceedings{kader16,
  title = {Contextual Embedding for Distributed Representations of Entities in a Text Corpus},
  author = {Kader, Md Abdul and  Boedihardjo, Arnold P. and  Naim, Sheikh Motahar and Hossain, M. Shahriar},
  abstract = {Distributed representations of textual elements in low dimensional vector space to 
	capture context has gained great attention recently. Current state-of-the-art word embedding
	techniques compute distributed representations using co-occurrences of words within a 
	contextual window discounting the flexibility to incorporate other contextual phenomena like
	temporal, geographical, and topical contexts. In this paper, we present a flexible framework
	that has the ability to leverage temporal, geographical, and topical information of documents 
	along with the textual content to produce more effective vector representations of
	entities or words within a document collection. The framework first captures contextual 
	relationships between entities collected from different relevant documents and then leverages
	these relationships to produce inputs of a graph, or to train a neural network to produce
	vectors for the entities. Through a set of rigorous experiments we test the performance of
	our approach and results show that our proposed solution can produce more meaningful
	vectors than the state-of-the-art methods.},
  pages = {35--50},
}
