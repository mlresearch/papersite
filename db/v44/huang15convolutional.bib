@InProceedings{huang15convolutional,
  title = {Convolutional Dictionary Learning through Tensor Factorization},
  author = {Huang, Furong and Anandkumar, Animashree},
  pages = {116-129},
  abstract = {Tensor methods have emerged as a powerful paradigm for consistent learning of many latent variable models such as topic models,  independent component analysis and dictionary learning. Model parameters are estimated via CP decomposition of the observed higher order input moments. In this paper, we extend tensor decomposition framework to models with invariances, such as convolutional dictionary models.    Our tensor decomposition algorithm is based on the popular alternating least squares (ALS) method, but with additional shift invariance constraints on the factors. We demonstrate that each ALS update can be computed efficiently using simple operations such as fast Fourier transforms and matrix multiplications. Our algorithm converges to models with better reconstruction error and is much faster, compared to the popular alternating minimization heuristic, where the filters  and activation maps are alternately updated.},
}
