@InProceedings{guan09a,
  title = {Sparse Probabilistic Principal Component Analysis},
  author = {Yue Guan and Jennifer Dy},
  pages = {185--192},
  abstract = {Principal component analysis (PCA) is a  popular dimensionality reduction algorithm.  However, it is not easy to interpret which of  the original features are important based on  the principal components. Recent methods  improve interpretability by sparsifying PCA  through adding an L1 regularizer. In this paper,  we introduce a probabilistic formulation  for sparse PCA. By presenting sparse PCA  as a probabilistic Bayesian formulation, we  gain the benet of automatic model selection.  We examine three dierent priors for achieving  sparsication: (1) a two-level hierarchical  prior equivalent to a Laplacian distribution  and consequently to an L1 regularization, (2)  an inverse-Gaussian prior, and (3) a Jerey's  prior. We learn these models by applying  variational inference. Our experiments verify  that indeed our sparse probabilistic model  results in a sparse PCA solution.},
  pdf = {http://jmlr.org/proceedings/papers/v5/guan09a/guan09a.pdf},
}
