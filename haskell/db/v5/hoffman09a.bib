@InProceedings{hoffman09a,
  title = {An Expectation Maximization Algorithm for Continuous Markov Decision Processes with Arbitrary Reward},
  author = {Matthew Hoffman and Nando de Freitas and Arnaud Doucet and Jan Peters},
  pages = {232--239},
  abstract = {We derive a new expectation maximization algorithm for policy optimization in  linear Gaussian Markov decision processes, where the reward function is  parameterised in terms of a flexible mixture of Gaussians. This approach  exploits both analytical tractability and numerical optimization. Consequently,  on the one hand, it is more flexible and general than closed-form solutions,  such as the widely used linear quadratic Gaussian (LQG) controllers. On the  other hand, it is more accurate and faster than optimization methods that rely  on approximation and simulation. Partial analytical solutions (though costly)  eliminate the need for simulation and, hence, avoid approximation error. The  experiments will show that for the same cost of computation, policy  optimization methods that rely on analytical tractability have higher value  than the ones that rely on simulation.},
  pdf = {http://jmlr.org/proceedings/papers/v5/hoffman09a/hoffman09a.pdf},
}
