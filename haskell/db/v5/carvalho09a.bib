@InProceedings{carvalho09a,
  title = {Handling Sparsity via the Horseshoe},
  author = {Carlos M. Carvalho and Nicholas G. Polson and James G. Scott},
  pages = {73--80},
  abstract = {This paper presents a general, fully Bayesian framework for sparse supervised-learning problems based on the horseshoe prior. The horseshoe prior is a member of the family of multivariate scale mixtures of normals, and is therefore closely related to widely used approaches for sparse Bayesian learning, including, among others, Laplacian priors (e.g. the LASSO) and Student-t priors (e.g. the relevance vector machine). The advantages of the horseshoe are its robustness at handling unknown sparsity and large outlying signals. These properties are justifed theoretically via a representation theorem and accompanied by comprehensive empirical experiments that compare its performance to benchmark alternatives.},
  pdf = {http://jmlr.org/proceedings/papers/v5/carvalho09a/carvalho09a.pdf},
}
