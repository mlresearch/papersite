@InProceedings{wang09a,
  title = {Non-Negative Semi-Supervised Learning},
  author = {Changhu Wang and Shuicheng Yan and Lei Zhang and Hongjiang Zhang},
  pages = {575--582},
  abstract = {The contributions of this paper are three-fold. First, we present a general formulation for reaping the benefits from both non-negative data factorization and semi-supervised learning, and the solution naturally possesses the characteristics of sparsity, robustness to partial occlusions, and greater discriminating power via extra unlabeled data. Then, an efficient multiplicative updating procedure is proposed along with its theoretic justification of the algorithmic convergency. Finally, the tensorization of this general formulation for non-negative semi-supervised learning is also briefed for handling tensor data of arbitrary order. Extensive experiments compared with the state-of-the-art algorithms for non-negative data factorization and semi-supervised learning demonstrate the algorithmic properties in sparsity, classification power, and robustness to image occlusions.},
  pdf = {http://jmlr.org/proceedings/papers/v5/wang09a/wang09a.pdf},
}
