@InProceedings{Eldridge15,
  author = {Eldridge, Justin and Belkin, Mikhail and Wang, Yusu},
  title = {Beyond Hartigan Consistency: Merge Distortion Metric for Hierarchical Clustering},
  pages = {588-606},
  abstract = {Hierarchical clustering is a popular method for analyzing data which associates
a tree to a dataset. Hartigan consistency has been used extensively as a
framework to analyze such clustering algorithms from a statistical point of
view. Still, as we show in the paper, a tree which is Hartigan consistent with a
given density can look very different than the correct limit tree. Specifically,
Hartigan consistency permits two types of undesirable configurations which we
term \emph{over-segmentation} and \emph{improper nesting}.  Moreover, Hartigan
consistency is a limit property and does not directly quantify difference
between trees.

In this paper we identify two limit properties, \emph{separation} and
\emph{minimality}, which address both over-segmentation and improper nesting and
together imply (but are not implied by) Hartigan consistency. We proceed to
introduce a \emph{merge distortion metric} between hierarchical clusterings and
show that convergence in our distance implies both separation and minimality. We
also prove that uniform separation and minimality imply convergence in the merge
distortion metric.  Furthermore, we show that our merge distortion metric is
stable under perturbations of the density.

Finally, we demonstrate applicability of these concepts by proving convergence
results for two clustering algorithms. First, we show convergence (and hence
separation and minimality) of the recent robust single linkage algorithm of
Chaudhuri and Dasgupta (2010). Second, we provide convergence results on
manifolds for  topological  split tree clustering.},
}
