@InProceedings{Shamir15,
  author = {Shamir, Ohad},
  title = {On the Complexity of Bandit Linear Optimization},
  pages = {1523-1551},
  abstract = {We study the attainable regret for online linear optimization
problems with bandit feedback, where unlike the full-information setting, the
player can only observe its own loss rather than the full loss vector. We
show that the price of bandit information in this setting can be as large as
$d$, disproving the well-known conjecture (Danie et al. (2007)) that the
regret for bandit linear optimization is at most $\sqrt{d}$ times the
full-information regret. Surprisingly, this is shown using ``trivial''
modifications of standard domains, which have no effect in the
full-information setting. This and other results we present highlight some
interesting differences between full-information and bandit learning, which
were not considered in previous literature.},
}
