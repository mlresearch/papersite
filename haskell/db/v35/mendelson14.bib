@InProceedings{mendelson14,
  author = {Mendelson, Shahar},
  title = {Learning without concentration},
  pages = {25-39},
  abstract = {We obtain sharp bounds on the convergence rate of Empirical Risk Minimization performed in a
  convex class and with respect to the squared loss, without any boundedness assumptions on class members
  or on the target.

 Rather than resorting to a concentration-based argument, the method relies on a `small-ball' assumption
 and thus holds for heavy-tailed sampling and heavy-tailed targets. Moreover, the resulting estimates scale
 correctly with the `noise level' of the problem.

 When applied to the classical, bounded scenario, the method always improves the known estimates.
},
}
