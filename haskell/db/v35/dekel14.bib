@InProceedings{dekel14,
  author = {Dekel, Ofer and Ding, Jian and Koren, Tomer and Peres, Yuval},
  title = {Online Learning with Composite Loss Functions},
  pages = {1214-1231},
  abstract = {We study a new class of online learning problems where each of the online algorithm's actions is assigned an adversarial value, and the loss of the algorithm at each step is a known and deterministic function of the values assigned to its recent actions. This class includes problems where the algorithm's loss is the \emph{minimum} over the recent adversarial values, the \emph{maximum} over the recent values, or a \emph{linear combination} of the recent values. We analyze the minimax regret of this class of problems when the algorithm receives bandit feedback, and prove that when the    \emph{minimum} or \emph{maximum} functions are used, the minimax regret is $\widetilde \Omega(T^{2/3})$ (so called \emph{hard} online learning problems), and when a linear function is used, the minimax regret is $\widetilde O(\sqrt{T})$ (so called \emph{easy} learning problems). Previously, the only online learning problem that was known to be provably hard was the multi-armed bandit with switching costs.},
}
