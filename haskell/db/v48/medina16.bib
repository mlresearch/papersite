@InProceedings{medina16,
  title = {No-Regret Algorithms for Heavy-Tailed Linear Bandits},
  author = {Andres Munoz Medina and Scott Yang},
  pages = {1642-1650},
  abstract = {We analyze the problem of linear bandits under heavy tailed noise. Most of of the work on linear bandits has been based on the assumption of bounded or sub-Gaussian noise. However, this assumption is often violated in common scenarios such as financial markets. We present two algorithms to tackle this problem: one based on dynamic truncation and one based on a median of means estimator. We show that, when the noise admits admits only a $1 + \epsilon$ moment, these algorithms are still able to achieve regret in $\widetilde{O}(T^{\frac{2 + \epsilon}{2(1 + \epsilon)}})$ and $\widetilde{O}(T^{\frac{1+ 2\epsilon}{1 + 3 \epsilon}})$ respectively. In particular, they guarantee sublinear regret as long as the noise has finite variance. We also present empirical results showing that our algorithms achieve a better performance than the current state of the art for bounded noise when the $L_\infty$ bound on the noise is large yet the $1 + \epsilon$ moment of the noise is small.},
}
