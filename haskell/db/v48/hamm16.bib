@InProceedings{hamm16,
  supplementary = {Supplementary:hamm16-supp.pdf},
  title = {Learning privately from multiparty data},
  author = {Jihun Hamm and Yingjun Cao and Mikhail Belkin},
  pages = {555-563},
  abstract = {Learning a classifier from private data distributed across multiple parties is an important problem that has many potential applications. How can we build an accurate and differentially private global classifier by combining locally-trained classifiers from different parties, without access to any party's private data? We propose to transfer the ``knowledge'' of the local classifier ensemble by first creating labeled data from auxiliary unlabeled data, and then train a global differentially private classifier. We show that majority voting is too sensitive and therefore propose a new risk weighted by class probabilities estimated from the ensemble. Relative to a non-private solution, our private solution has a generalization error bounded by $O(\epsilon^{-2} M^{-2})$. This allows strong privacy without performance loss when the number of participating parties M is large, such as in crowdsensing applications. We demonstrate the performance of our framework with realistic tasks of activity recognition, network intrusion detection, and malicious URL detection.},
}
