@InProceedings{wang13c,
  pdf = {http://jmlr.org/proceedings/papers/v31/wang13c.pdf},
  title = {Block Regularized Lasso for Multivariate Multi-Response Linear Regression},
  author = {Wang, Weiguang and Liang, Yingbin and Xing, Eric},
  pages = {608--617},
  abstract = {The multivariate multi-response (MVMR) linear regression problem is investigated, in which design matrices can be distributed differently across $K$ linear regressions. The support union of $K$ $p$-dimensional regression vectors are recovered via block regularized Lasso which uses the $l_1/l_2$ norm for regression vectors across $K$ tasks. Sufficient and necessary conditions to guarantee successful recovery of the support union are characterized. More specifically, it is shown that under certain conditions on the distributions of design matrices, if $n > c_{p1} \psi(B^*,\Sigma^{(1:K)})\log(p-s)$ where $c_{p1}$ is a constant and $s$ is the size of the support set, then the $l_1/l_2$ regularized Lasso correctly recovers the support union; and if $n < c_{p2} \psi(B^*,\Sigma^{(1:K)})\log(p-s)$ where $c_{p2}$ is a constant, then the $l_1/l_2$ regularized Lasso fails to recover the support union. In particular, $\psi(B^*,\Sigma^{(1:K)})$ captures the sparsity of $K$ regression vectors and the statistical properties of the design matrices. Numerical results are provided to demonstrate the advantages of joint support union recovery using multi-task Lasso problem over studying each problem individually.},
}
