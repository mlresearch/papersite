@InProceedings{luo13b,
  pdf = {http://jmlr.org/proceedings/papers/v31/luo13b.pdf},
  title = {Fast Near-GRID Gaussian Process Regression},
  author = {Luo, Yuancheng and Duraiswami, Ramani},
  pages = {424--432},
  abstract = {\emph{Gaussian process regression} (GPR) is a powerful non-linear technique for Bayesian inference and prediction. One drawback is its O($N^3$) computational complexity for both prediction and hyperparameter estimation for $N$ input points which has led to much work in sparse GPR methods. In case that the covariance function is expressible as a \emph{tensor product kernel} (TPK) and the inputs form a multidimensional grid, it was shown that the costs for exact GPR can be reduced to a sub-quadratic function of $N$. We extend these exact fast algorithms to sparse GPR and remark on a connection to \emph{Gaussian process latent variable models} (GPLVMs). In practice, the inputs may also violate the multidimensional grid constraints so we pose and efficiently solve missing and extra data problems for both exact and sparse grid GPR. We demonstrate our method on synthetic, text scan, and magnetic resonance imaging (MRI) data reconstructions.},
}
