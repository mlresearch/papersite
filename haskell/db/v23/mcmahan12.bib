@InProceedings{mcmahan12,
  title = {Open Problem: Better Bounds for Online Logistic Regression},
  author = {H.   Brendan McMahan and Matthew Streeter},
  pages = {44.1--44.3},
  abstract = {Known algorithms applied to online logistic regression on a feasible set of \emph{L}_{2} diameter \emph{D} achieve regret bounds like \emph{O}(\emph{e^{D}} log \emph{T}) in one dimension, but we show a bound of \emph{O}(âˆš\emph{D}  + log \emph{T}) is possible in a binary 1-dimensional problem. Thus, we pose the following question: Is it possible to achieve a regret bound for online logistic regression that is \emph{O}(poly(\emph{D}) log(\emph{T}))? Even if this is not possible in general, it would be interesting to have a bound that reduces to our bound in the one-dimensional case.},
  pdf = {http://jmlr.org/proceedings/papers/v23/mcmahan12/mcmahan12.pdf},
}
