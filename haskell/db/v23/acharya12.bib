@InProceedings{acharya12,
  title = {Competitive Classification and Closeness Testing},
  author = {Jayadev Acharya and Hirakendu Das and Ashkan Jafarpour and Alon Orlitsky and Shengjun Pan and Ananda Suresh},
  pages = {22.1--22.18},
  abstract = {We study the problems of \emph{classification} and \emph{closeness testing}. A \emph{classifier} associates a test sequence with the one of two training sequences that was generated by the same distribution. A \emph{closeness test} determines whether two sequences were generated by the same or by different distributions. For both problems all natural algorithms are \emph{symmetric} -- they make the same decision under all symbol relabelings. With no assumptions on the distributions' support size or relative distance, we construct a classifier and closeness test that require at most $O(n^{3/2})$ samples to attain the $n$-sample accuracy of the best symmetric classifier or closeness test designed with knowledge of the underlying distributions. Both algorithms run in time linear in the number of samples. Conversely we also show that for any classifier or closeness test, there are distributions that require $\Omega(n^{7/6})$ samples to achieve the $n$-sample accuracy of the best symmetric algorithm that knows the underlying distributions.},
  pdf = {http://jmlr.org/proceedings/papers/v23/acharya12/acharya12.pdf},
}
