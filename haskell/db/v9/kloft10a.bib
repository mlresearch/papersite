@InProceedings{kloft10a,
  title = {Online Anomaly Detection under Adversarial Impact},
  author = {Marius Kloft and Pavel Laskov},
  pages = {405--412},
  abstract = {Security analysis of learning algorithms is gaining increasing importance, especially since they have become target of deliberate obstruction in certain applications. Some security-hardened algorithms have been previously proposed for supervised learning; however, very little is known about the behavior of anomaly detection methods in such scenarios. In this contribution, we analyze the performance of a particular method---online centroid anomaly detection---in the presence of adversarial noise. Our analysis addresses three key security-related issues: derivation of an optimal attack, analysis of its efficiency and constraints. Experimental evaluation carried out on real HTTP and exploit traces confirms the tightness of our theoretical bounds.},
  pdf = {http://jmlr.org/proceedings/papers/v9/kloft10a/kloft10a.pdf},
  supplementary = {Supplementary:http://jmlr.org/proceedings/papers/v9/kloft10a/kloft10aSupple.pdf},
}
