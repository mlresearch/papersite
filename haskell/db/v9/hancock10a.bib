@InProceedings{hancock10a,
  title = {Boosted Optimization for Network Classification},
  author = {Timothy Hancock and Hiroshi Mamitsuka},
  pages = {305--312},
  abstract = {In this paper we propose a new classification algorithm designed for application on complex networks motivated by algorithmic similarities between boosting learning and message passing.  We consider a network classifier as a logistic regression where the variables define the nodes and the interaction effects define the edges.  From this definition we represent the problem as a factor graph of local exponential loss functions.  Using the factor graph representation it is possible to interpret the network classifier as an ensemble of individual node classifiers.  We then combine ideas from boosted learning with network optimization algorithms to define two novel algorithms, Boosted Expectation Propagation (BEP) and Boosted Message Passing (BMP).  These algorithms optimize the global network classifier performance by locally weighting each node classifier by the error of the surrounding network structure.  We compare the performance of BEP and BMP to logistic regression as well state of the art penalized logistic regression models on simulated grid structured networks.  The results show that using local boosting to optimize the performance of a network classifier increases classification performance and is especially powerful in cases when the whole network structure must be considered for accurate classification.},
  pdf = {http://jmlr.org/proceedings/papers/v9/hancock10a/hancock10a.pdf},
}
