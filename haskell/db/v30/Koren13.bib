@InProceedings{Koren13,
  pdf = {http://jmlr.org/proceedings/papers/v30/Koren13.pdf},
  title = {Open Problem: Fast Stochastic Exp-Concave Optimization  },
  author = {Tomer Koren},
  pages = {1073-1075},
  abstract = {Stochastic exp-concave optimization is an important primitive in machine learning that captures several fundamental problems, including linear regression, logistic regression and more. The exp-concavity property allows for fast convergence rates, as compared to general stochastic optimization.  However, current algorithms that attain such rates scale poorly with the dimension $n$ and run in time $O(n^4)$, even on very simple instances of the problem.  The question we pose is whether it is possible to obtain fast rates for exp-concave functions using more computationally-efficient algorithms. },
  section = {open-problem}
}
