@InProceedings{huang14,
  supplementary = {Supplementary:huang14-supp.pdf},
  title = {{A Finite-Sample Generalization Bound for Semiparametric Regression: Partially Linear Models}},
  author = {Huang, Ruitong and Szepesvari, Csaba},
  pages = {402-410},
  abstract = {In this paper we provide generalization bounds for semiparametric regression with the so-called partially linear models where the regression function is written as the sum of a linear parametric and a nonlinear, nonparametric function, the latter taken from a some set $\mathcal{H}$ with finite entropy-integral. The problem is technically challenging because the parametric part is unconstrained and the model is underdetermined, while the response is allowed to be unbounded with subgaussian tails. Under natural regularity conditions, we bound the generalization error as a function of the metric entropy of $\mathcal{H}$ and the dimension of the linear model. Our main tool is a ratio-type concentration inequality for increments of empirical processes, based on which we are able to give an exponential tail bound on the size of the parametric component. We also provide a comparison to alternatives of this technique and discuss why and when the unconstrained parametric part in the model may cause a problem in terms of the expected risk. We also explain by means of a specific example why this problem cannot be detected using the results of classical asymptotic analysis often seen in the statistics literature.},
}
