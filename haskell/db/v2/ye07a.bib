@InProceedings{ye07a,
  title = {SVM versus Least Squares SVM},
  author = {Jieping Ye and Tao Xiong},
  pages = {644--651},
  abstract = {We study the relationship between Support Vector Machines (SVM) and Least Squares SVM (LS-SVM). Our main result shows that under mild conditions, LS-SVM for binaryclass classifications is equivalent to the hard margin SVM based on the well-known Mahalanobis distance measure. We further study the asymptotics of the hard margin SVM when the data dimensionality tends to infinity with a fixed sample size. Using recently developed theory on the asymptotics of the distribution of the eigenvalues of the covariance matrix, we show that under mild conditions, the equivalence result holds for the traditional Euclidean distance measure. These equivalence results are further extended to the multi-class case. Experimental results confirm the presented theoretical analysis.},
  pdf = {http://jmlr.org/proceedings/papers/v2/ye07a/ye07a.pdf},
}
