@InProceedings{krummenacher13,
  pdf = {http://jmlr.org/proceedings/papers/v28/krummenacher13.pdf},
  supplementary = {Supplementary:krummenacher13-supp.pdf},
  number = {2},
  section = {cycle-2},
  title = {Ellipsoidal Multiple Instance Learning},
  author = {Krummenacher, Gabriel and Soon Ong, Cheng and Buhmann, Joachim},
  pages = {73-81},
  abstract = {We propose a large margin method for asymmetric learning with ellipsoids, called eMIL, suited to multiple instance learning (MIL). We derive the distance between ellipsoids and the hyperplane, generalising the standard support vector machine. Negative bags in MIL contain only negative instances, and we treat them akin to uncertain observations in the robust optimisation framework. However, our method allows positive bags to cross the margin, since it is not known which instances within are positive.  We show that representing bags as ellipsoids under the introduced distance is the most robust solution when treating a bag as a random variable with finite mean and covariance. Two algorithms are derived to solve the resulting non-convex optimization problem: a concave-convex procedure and a quasi-Newton method. Our method achieves competitive results on benchmark datasets. We introduce a MIL dataset from a real world application of detecting wheel defects from multiple partial observations, and show that eMIL outperforms competing approaches.},
}
