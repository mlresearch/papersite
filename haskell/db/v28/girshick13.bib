@InProceedings{girshick13,
  pdf = {http://jmlr.org/proceedings/papers/v28/girshick13.pdf},
  supplementary = {Supplementary:girshick13-supp.pdf},
  title = {Discriminatively Activated Sparselets},
  number = {1},
  section = {cycle-1},
  author = {Girshick, Ross and Song, Hyun Oh and Darrell, Trevor},
  pages = {196-204},
  abstract = {Shared representations are highly appealing due to their potential  for gains in computational and statistical efficiency.  Compressing  a shared representation leads to greater computational savings, but  at the same time can severely decrease performance on a target task.  Recently, sparselets (Song et al., 2012) were introduced as a new  shared intermediate representation for multiclass object detection  with deformable part models (Felzenszwalb et al., 2010a), showing  significant speedup factors, but with a large decrease in task  performance.  In this paper we describe a new training framework  that learns which sparselets to activate in order to optimize a  discriminative objective, leading to larger speedup factors with  no decrease in task performance.  We first reformulate sparselets  in a general structured output prediction framework, then analyze  when sparselets lead to computational efficiency gains, and lastly  show experimental results on object detection and image classification  tasks.  Our experimental results demonstrate that discriminative  activation substantially outperforms the previous reconstructive  approach which, together with our structured output prediction  formulation, make sparselets broadly applicable and significantly  more effective.},
}
