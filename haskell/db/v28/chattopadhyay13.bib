@InProceedings{chattopadhyay13,
  pdf = {http://jmlr.org/proceedings/papers/v28/chattopadhyay13.pdf},
  supplementary = {Supplementary:chattopadhyay13-supp.pdf},
  number = {3},
  section = {cycle-3},
  title = {Joint Transfer and Batch-mode Active Learning},
  author = {Chattopadhyay, Rita and Fan, Wei and Davidson, Ian and Panchanathan, Sethuraman and Ye, Jieping},
  pages = {253-261},
  abstract = {Active learning and transfer learning are two different methodologies that address the common  problem of insufficient labels. Transfer learning addresses this problem by using the knowledge gained from a related and already labeled data source, whereas active learning focuses on selecting a small set of informative samples  for manual annotation. Recently, there has been much interest in developing frameworks that combine both transfer and active learning  methodologies. A few such frameworks reported in literature perform transfer and active learning in two separate stages. In this work, we present an integrated framework that performs transfer and active learning simultaneously by solving a  single convex optimization problem. The proposed framework computes the weights of source domain data and selects the samples from the target domain data simultaneously, by minimizing a common objective of reducing distribution difference between the data set consisting of reweighted source and the queried target domain data and the set of unlabeled target domain data. Comprehensive experiments on three real world data sets demonstrate that the proposed method improves the classification accuracy by 5\% to  10\% over the existing two-stage approach},
}
