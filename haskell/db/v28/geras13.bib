@InProceedings{geras13,
  pdf = {http://jmlr.org/proceedings/papers/v28/geras13.pdf},
  number = {3},
  section = {cycle-3},
  title = {Multiple-source cross-validation},
  author = {Geras, Krzysztof and Sutton, Charles},
  pages = {1292-1300},
  abstract = {Cross-validation is an essential tool in machine learning and statistics. The typical procedure, in which data points are randomly assigned to one of the test sets, makes an implicit assumption that the data are exchangeable. A common case in which this does not hold is when the data come from multiple sources, in the sense used in transfer learning. In this case it is common to arrange the cross-validation procedure in a way that takes the source structure into account. Although common in practice, this procedure does not appear to have been theoretically analysed. We present new estimators of the variance of the cross-validation, both in the multiple-source setting and in the standard iid setting. These new estimators allow for much more accurate confidence intervals and hypothesis tests to compare algorithms.},
}
