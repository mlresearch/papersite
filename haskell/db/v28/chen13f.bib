@InProceedings{chen13f,
  pdf = {http://jmlr.org/proceedings/papers/v28/chen13f.pdf},
  supplementary = {Supplementary:chen13f-supp.pdf},
  number = {3},
  section = {cycle-3},
  title = {Optimistic Knowledge Gradient Policy for Optimal Budget Allocation in Crowdsourcing},
  author = {Chen, Xi and Lin, Qihang and Zhou, Dengyong},
  pages = {64-72},
  abstract = {In real crowdsourcing applications, each label from a crowd usually comes  with a certain cost. Given a pre- fixed amount of budget, since different tasks have different ambiguities and different workers have different expertises, we want to  find an optimal way to allocate the budget among instance-worker pairs such that the overall label quality can be maximized. To address this issue, we start from the simplest setting in which all workers are assumed to be perfect. We formulate the problem as a Bayesian Markov Decision Process (MDP). Using the dynamic programming (DP) algorithm, one can obtain the optimal allocation policy for a given budget. However,  DP is computationally intractable. To solve the computational challenge, we propose a novel approximate policy which is called optimistic knowledge gradient. It is practically efficient while theoretically its consistency can be guaranteed.  We then extend  the MDP framework to deal with inhomogeneous workers and tasks with contextual information available.  The experiments on both simulated and real data  demonstrate the superiority of our method.},
}
