@InProceedings{yuhui13,
  pdf = {http://jmlr.org/proceedings/papers/v28/yuhui13.pdf},
  number = {2},
  section = {cycle-2},
  title = {Direct Modeling of Complex Invariances for Visual Object Features},
  author = {Yu Hui, Ka},
  pages = {352-360},
  abstract = {View-invariant object representations created from feature pooling networks have been widely adopted in state-of-the-art visual recognition systems. Recently, the research community seeks to improve these view-invariant representations further by additional invariance and receptive field learning, or by taking on the challenge of processing massive amounts of learning data. In this paper we consider an alternate strategy of directly modeling complex invariances of object features. While this may sound like a naive and inferior approach, our experiments show that this approach can achieve competitive and state-of-the-art accuracy on visual recognition data sets such as CIFAR-10 and STL-10. We present an highly applicable dictionary learning algorithm on complex invariances that can be used in most feature pooling network settings. It also has the merits of simplicity and requires no additional tuning. We also discuss the implication of our experiment results concerning recent observations on the usefulness of pre-trained features, and the role of direct invariance modeling in invariance learning.},
}
