@InProceedings{trandinh13,
  pdf = {http://jmlr.org/proceedings/papers/v28/trandinh13.pdf},
  supplementary = {Supplementary:trandinh13-supp.pdf},
  number = {2},
  section = {cycle-2},
  title = {A proximal {N}ewton framework for composite minimization: Graph learning without {C}holesky decompositions and matrix inversions},
  author = {Tran Dinh, Quoc and Kyrillidis, Anastasios and Cevher, Volkan},
  pages = {271-279},
  abstract = {We propose an algorithmic framework for convex minimization problems of composite functions with two terms:  a self-concordant part and a possibly nonsmooth regularization part.  Our method is a new proximal Newton algorithm with local quadratic convergence rate. As a specific problem instance, we consider sparse precision matrix estimation problems in graph learning. Via a careful dual formulation and a novel analytic step-size selection, we instantiate an algorithm within our framework for graph learning that avoids Cholesky decompositions and matrix inversions, making it attractive for parallel and distributed implementations. },
}
