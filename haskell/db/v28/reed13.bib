@InProceedings{reed13,
  pdf = {http://jmlr.org/proceedings/papers/v28/reed13.pdf},
  supplementary = {Supplementary:reed13-supp.pdf},
  number = {3},
  section = {cycle-3},
  title = {Scaling the Indian Buffet Process via Submodular Maximization},
  author = {Reed, Colorado and Zoubin, Ghahramani},
  pages = {1013-1021},
  abstract = {Inference for latent feature models is inherently difficult as the inference space grows exponentially with the size of the input data and number of latent features. In this work, we use Kurihara & Wellings (2008)'s maximization-expectation framework to perform approximate MAP inference for linear-Gaussian latent feature models with an Indian Buffet Process (IBP) prior. This formulation yields a submodular function of the features that corresponds to a lower bound on the model evidence. By adding a constant to this function, we obtain a nonnegative submodular function that can be maximized via a greedy algorithm that obtains at least a 1/3-approximation to the optimal solution. Our inference method scales linearly with the size of the input data, and we show the efficacy of our method on the largest datasets currently analyzed using an IBP model. },
}
