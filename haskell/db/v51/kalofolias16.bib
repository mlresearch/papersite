@InProceedings{kalofolias16,
  supplementary = {Supplementary:kalofolias16-supp.pdf},
  title = {How to Learn a Graph from Smooth Signals},
  author = {Kalofolias, Vassilis},
  pages = {920-929},
  abstract = {We propose a framework to learn the graph structure underlying a set of smooth signals. Given $X\in\mathbb{R}^{m\times n}$ whose rows reside on the vertices of an unknown graph, we learn the edge weights $w\in\mathbb{R}_+^{m(m-1)/2}$ under the smoothness assumption that ${\rm tr}{X^\top LX}$ is small, where $L$ is the graph Laplacian.  We show that the problem is a weighted $\ell$-1 minimization that leads to naturally sparse solutions. We prove that the standard graph construction with Gaussian weights $w_{ij} = \exp(-\frac{1}{\sigma^2}\|x_i-x_j\|^2)$ and the previous state of the art are special cases of our framework. We propose a new model and present efficient, scalable primal-dual based algorithms both for this and the previous state of the art, to evaluate their performance on artificial and real data. The new model performs best in most settings.},
}
