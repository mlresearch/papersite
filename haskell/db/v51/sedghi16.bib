@InProceedings{sedghi16,
  supplementary = {Supplementary:sedghi16-supp.pdf},
  title = {Provable Tensor Methods for Learning Mixtures of Generalized Linear Models},
  author = {Sedghi, Hanie and Janzamin, Majid and Anandkumar, Anima},
  pages = {1223-1231},
  abstract = {We consider the problem of learning mixtures of generalized linear models (GLM) which arise in   classification and regression problems.   Typical learning  approaches such as expectation maximization (EM) or variational Bayes  can get stuck in spurious local optima. In contrast,  we present a tensor decomposition method which is guaranteed to correctly recover the parameters. The key insight is to employ certain feature transformations of the input, which depend on the input generative model. Specifically, we employ score function tensors of the input  and compute their cross-correlation with the response variable.   We establish that the decomposition of this tensor consistently recovers the parameters, under mild non-degeneracy conditions.  We demonstrate that the computational and  sample complexity of our method is a low order polynomial of the input and the latent  dimensions.},
}
