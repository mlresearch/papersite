@InProceedings{hernandez-lobato16,
  supplementary = {Supplementary:hernandez-lobato16-supp.zip},
  title = {Scalable Gaussian Process Classification via Expectation Propagation},
  author = {Hernandez-Lobato, Daniel and Hernandez-Lobato, Jose Miguel},
  pages = {168-176},
  abstract = {Variational methods have been recently considered for scaling the training process of Gaussian process classifiers to large datasets. As an alternative, we describe here how to train these classifiers efficiently using expectation propagation (EP). The proposed EP method allows to train Gaussian process classifiers on very large datasets, with millions of instances, that were out of the reach of previous implementations of EP. More precisely, it can be used for (i) training in a distributed fashion where the data instances are sent to different nodes in which the required computations are carried out, and for (ii) maximizing an estimate of the marginal likelihood using a stochastic approximation of the gradient. Several experiments involving large datasets show that the method described is competitive with the variational approach.},
}
