@InProceedings{jamieson16,
  supplementary = {Supplementary:jamieson16-supp.pdf},
  title = {Non-stochastic Best Arm Identification and Hyperparameter Optimization},
  author = {Jamieson, Kevin and Talwalkar, Ameet},
  pages = {240-248},
  abstract = {Motivated by the task of hyperparameter optimization, we introduce the {\em non-stochastic best-arm identification problem}. We identify an attractive algorithm  for this setting that makes no assumptions on the convergence behavior of the arms' losses, has no free-parameters to adjust, provably outperforms the uniform allocation baseline in favorable conditions, and performs comparably (up to $\log$ factors) otherwise. Next, by leveraging the iterative nature of many  learning algorithms, we cast hyperparameter optimization as an instance of non-stochastic best-arm identification. Our empirical results show that, by allocating more resources to promising hyperparameter settings, our approach achieves comparable test accuracies an order of magnitude faster than the uniform strategy. The robustness and simplicity of our approach makes it well-suited to ultimately replace the uniform strategy currently used in most machine learning software packages.},
}
