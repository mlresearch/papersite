@InProceedings{nikulin12a,
  pdf = {http://jmlr.org/proceedings/papers/v27/nikulin12a.pdf},
  title = {Unsupervised dimensionality reduction via gradient-based matrix factorization with two adaptive learning rates},
  author = {V. Nikulin and T.-H. Huang},
  pages = {181--194},
  abstract = {The high dimensionality of the data, the expressions of thousands of features in a much smaller number of samples, presents challenges that affect applicability of the analytical results. In principle, it would be better to describe the data in terms of a small number of meta-features, derived as a result of matrix factorization, which could reduce noise while still capturing the essential features of the data. Three novel and mutually relevant methods are presented in this paper: 1) gradient-based matrix factorization with two adaptive learning rates (in accordance with the number of factor matrices) and their automatic updates; 2) nonparametric criterion for the selection of the number of factors; and 3) nonnegative version of the gradient-based matrix factorization which doesnât require any extra computational costs in difference to the existing methods. We demonstrate effectiveness of the proposed methods to the supervised classification of gene expression data.},
}
