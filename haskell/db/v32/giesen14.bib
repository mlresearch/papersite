@InProceedings{giesen14,
  title = {Robust and Efficient Kernel Hyperparameter Paths with Guarantees},
  author = {Joachim Giesen and Soeren Laue and Patrick Wieschollek},
  pages = {1296-1304},
  abstract = {Algorithmically, many machine learning tasks boil down to solving  parameterized optimization problems. Finding good values for the  parameters has significant influence on the statistical performance  of these methods. Thus supporting the choice of parameter values  algorithmically has received quite some attention recently,  especially algorithms for computing the whole solution path of  parameterized optimization problem. These algorithms can be used,  for instance, to track the solution of a regularized learning  problem along the regularization parameter path, or for tracking the  solution of kernelized problems along a kernel hyperparameter  path. Since exact path following algorithms can be numerically  unstable, robust and efficient approximate path tracking algorithms  became popular for regularized learning problems. By now algorithms  with optimal path complexity are known for many regularized learning  problems. That is not the case for kernel hyperparameter path  tracking algorithms, where the exact path tracking algorithms can  also suffer from numerical instabilities. The robust approximation  algorithms for regularization path tracking can not be used directly  for kernel hyperparameter path tracking problems since the latter  fall into a different problem class. Here we address this problem by  devising a robust and efficient path tracking algorithm that can  also handle kernel hyperparameter paths and has asymptotically  optimal complexity. We use this algorithm to compute approximate  kernel hyperparamter solution paths for support vector machines and  robust kernel regression. Experimental results for this problem  applied to various data sets confirms the theoretical complexity  analysis.},
  section = {cycle-2},
}
