@InProceedings{torkamani14,
  supplementary = {Supplementary:torkamani14-supp.pdf},
  title = {On Robustness and Regularization of Structural Support Vector Machines},
  author = {Mohamad Ali Torkamani and Daniel Lowd},
  pages = {577-585},
  abstract = {Previous analysis of binary SVMs has demonstrated a deep connection between robustness to perturbations over uncertainty sets and regularization of the  weights.  In this paper, we explore the problem of learning robust  models for structured prediction problems.  We first formulate the problem  of learning robust structural SVMs when there are perturbations in  the feature space.  We consider two different classes of uncertainty sets for the perturbations: ellipsoidal uncertainty sets and polyhedral uncertainty sets. In both cases, we show that the robust optimization problem is equivalent to the non-robust formulation with an additional regularizer. For the ellipsoidal uncertainty set, the additional regularizer is based on the dual norm of the norm that constrains the ellipsoidal uncertainty. For the polyhedral uncertainty set, we show that the robust optimization problem is equivalent to adding a linear regularizer in a transformed weight space related to the linear constraints of the polyhedron. We also show that  these constraint sets can be combined and demonstrate a number of  interesting special cases.  This represents the first theoretical  analysis of robust optimization of structural support vector machines. Our experimental results show that our method outperforms the nonrobust structural SVMs on real world data when the test data distributions is drifted from the training data distribution.},
  section = {cycle-2},
}
