@Proceedings{MLIS-2015,
    booktitle = {Proceedings of The 4th Workshop on Machine Learning for Interactive Systems},
    editor = {Cuay\'ahuitl, Heriberto and Dethlefs, Nina and Frommberger, Lutz and Van Otterlo, Martijn and Pietquin, Olivier},
    volume = {43},
    year = {2015},
    shortname = {MLIS}
}

@InProceedings{piot15,
    title = {Imitation Learning Applied to Embodied Conversational Agents},
    author = {Piot Bilal and Pietquin, Olivier and Geist, Matthieu},
    pages = {1-5},
    abstract = {Embodied Conversational Agents (ECAs) are emerging as a key component to allow human interact with machines. Applications are numerous and ECAs can reduce the aversion to interact with a machine by providing user-friendly interfaces. Yet, ECAs are still unable to produce social signals appropriately during their interaction with humans, which tends to make the interaction less instinctive. Especially, very little attention has been paid to the use of laughter in human-avatar interactions despite the crucial role played by laughter in human-human interaction. In this paper, methods for predicting when and how to laugh during an interaction for an ECA are proposed. Different Imitation Learning (also known as Apprenticeship Learning) algorithms are used in this purpose and a regularized classification algorithm is shown to produce good behavior on real data.}
}

@InProceedings{sharma15,
    title = {Efficient Real-Time Pixelwise Object Class Labeling for Safe Human-Robot Collaboration in Industrial Domain},
    author = {Sharma, Vivek and Dittrich, Frank and Yildirim-Yayilgan, Sule and Van Gool, Luc},
    pages = {6-14},
    abstract = {In this paper, we use a random decision forests (RDF) classifier with a conditional random field (CRF) for pixelwise object class labeling of real-world scenes. Our ultimate goal is to develop an application which will provide safe human-robot collaboration (SHRC) and interaction (SHRI) in industrial domain. Such an application has many aspects to consider and in this work, we particularly focus on minimizing the mislabeling of human and object parts using depth measurements. This aspect will be important in modelling human/robot and object interactions in future work. Our approach is driven by three key objectives namely computational efficiency, robustness, and time efficiency (i.e. real-time). Due to the ultimate goal of reducing the risk of human-robot interventions. Our data set is depth measurements stored in depth maps. The object classes are human body-parts (head, body, upper-arm, lower-arm, hand, and legs), table, chair, plant, and storage based on industrial domain. We train an RDF classifier on the depth measurements contained in the depth maps. In this context, the output of random decision forests is a label assigned to each depth measurement. The misclassification of labels assigned to depth measurements is minimized by modeling the labeling problem on a pairwise CRF. The RDF classifier with its CRF extension (optimal predictions obtained using graph cuts extended over RDF predictions) has been evaluated for its performance for pixelwise object class segmentation. The evaluation results show that the CRF extension improves the performance measure by approximately 10.8\% in F1-measure over the RDF performance measures.}
}

@InProceedings{senft15,
    title = {Human-Guided Learning of Social Action Selection for Robot-Assisted Therapy},
    author = {Senft, Emmanuel and Baxter, Paul and Belpaeme, Tony},
    pages = {15-20},
    abstract = {This paper presents a method for progressively increasing autonomous action selection capabilities in sensitive environments, where random exploration-based learning is not desirable, using guidance provided by a human supervisor. We describe the global framework and a simulation case study based on a scenario in Robot Assisted Therapy for children with Autism Spectrum Disorder. This simulation illustrates the functional features of our proposed approach, and demonstrates how a system following these principles adapts to different interaction contexts while maintaining an appropriate behaviour for the system at all times.}
}

@InProceedings{pasquale15,
    title = {Teaching iCub to recognize objects using deep Convolutional Neural Networks},
    author = {Pasquale, Giulia and Ciliberto, Carlo and Odone, Francesca and Rosasco, Lorenzo and Natale, Lorenzo},
    pages = {21-25},
    abstract = {Providing robots with accurate and robust visual recognition capabilities in the real-world today is a challenge which prevents the use of autonomous agents for concrete applications. Indeed, the majority of tasks, as manipulation and interaction with other agents, critically depends on the ability to visually recognize the entities involved in a scene. At the same time, computer vision systems based on deep Convolutional Neural Networks (CNNs) are marking a breakthrough in fields as large-scale image classification and retrieval. In this work we investigate how latest results on deep learning can advance the visual recognition capabilities of a robotic platform (the iCub humanoid robot) in a real-world scenario. We benchmark the performance of the resulting system on a new dataset of images depicting 28 objects, named iCubWorld28, that we plan on releasing. As in the spirit of the iCubWorld dataset series, this has been collected in a framework reflecting the typical iCub’s daily visual experience. Moreover, in this release we provide four different acquisition sessions, to test incremental learning capabilities over multiple days. Our study addresses the question: how many objects can the iCub recognize today?}
}

@InProceedings{rolf15,
    title = {Latent Goal Analysis for Dimension Reduction in Reinforcement Learning},
    author = {Rolf, Matthias and Asada, Minoru},
    pages = {26-30},
    abstract = {In contrast to reinforcement learning, adaptive control formulations [Nguyen-Tuong and Peters, 2011] already come with expressive and typically low-dimensional goal and task representations, which have been generally considered more expressive than the RL setting [Kaelbling et al., 1996]. Goal and actual values in motor control define a relation similar [Rolf and Steil, 2014] to actual and target outputs in classical supervised learning settings by providing “directional information” in contrast to a mere “magnitude of an error” in reinforcement learning [Barto, 1994]. Recent work [Rolf and Asada, 2014] however showed that these two problem formulations can be transformed into each other. Hence, highly descriptive task representations can be extracted out of reinforcement learning problems by transforming them into adaptive control problems. After introducing the method called Latent Goal Analysis, we discuss the possible application of this approach as dimension reduction technique in reinforcement learning. Experimental results in a web recommender scenario confirm the potential of this technique.}
}

@InProceedings{ghosh15,
    title = {Online Mean Field Approximation for Automated Experimentation},
    author = {Ghosh, Shaona and Pr\"ugel-Bennett, Adam},
    pages = {31-35},
    abstract = {In this paper, we propose a semi-supervised online graph labelling method that affords early learning capability. We use mean field approximation for predicting the unknown labels of the vertices of the graph with high accuracy on the standard benchmark datasets. The minimum cut is the energy function of our probabilistic model that encodes the uncertainty about the labels of the vertices. Our method shows that it can learn early given any choice of experiments that may take place in the automated experimentation systems used for scientific discovery.}
}

@InProceedings{vepakomma15,
    title = {Iterative Embedding with Robust Correction using Feedback of Error Observed},
    author = {Vepakomma, Praneeth and Elgammal, Ahmed},
    pages = {36-40},
    abstract = {Nonlinear dimensionality reduction techniques of today are highly sensitive to outliers. Almost all of them are spectral methods and differ from each other over their treatment of the notion of neighborhood similarities computed amongst the high-dimensional input data points. These techniques aim to preserve the notion of this similarity structure in the low-dimensional output. The presence of unwanted outliers in the data directly influences the preservation of these neighborhood similarities amongst the majority of the non-outlier data, as these points ocuring in majority need to simultaneously satisfy their neighborhood similarities they form with the outliers while also satisfying the similarity structure they form with the non-outlier data. This issue disrupts the intrinsic structure of the manifold on which the majority of the non-outlier data lies when preserved via a homeomorphism on a low-dimensional manifold. In this paper we come up with an iterative algorithm that analytically solves for a non-linear embedding with mono- tonic improvements after each iteration. As an application of this iterative manifold learning algorithm, we come up with a framework that decomposes the pair-wise error observed between all pairs of points and update the neighborhood similarity matrix dynamically to downplay the effect of the outliers, over the majority of the non-outlier data being embedded into a lower dimension.}
}

@InProceedings{sokolov15,
    title = {Coactive Learning for Interactive Machine Translation},
    author = {Sokolov, Artem and Riezler, Stefan and Cohen, Shay B.},
    pages = {41-45},
    abstract = {Coactive learning describes the interaction between an online structured learner and a human user who corrects the learner by responding with weak feedback, that is, with an improved, but not necessarily optimal, structure. We apply this framework to discriminative learning in interactive machine translation. We present a generalization to latent variable models and give regret and generalization bounds for online learning with a feedback-based latent perceptron. We show experimentally that learning from weak feedback in machine translation leads to convergence in regret and translation error.}
}

@InProceedings{ilves15,
    title = {Visualizing User Model in Exploratory Search Tasks},
    author = {Ilves, Kalle and Medlar, Alan and Glowacka, Dorota},
    pages = {46-47},
    abstract = {We present our ongoing work on an interactive exploratory information retrieval system designed to explain to the user the reasons for its predictions and help the user to build a mental model to predict how the system will behave. Users indicate which documents interest them and reinforcement learning is used to model the user by allowing the system to trade off between exploration and exploitation.}
}

